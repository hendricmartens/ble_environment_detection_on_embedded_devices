{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ble_environment_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gq9uTbZ36ns4"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "! pip install tensorflow==2.4.0\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "clear_output()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QSJ0EVOh1b-"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math as m\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import copy\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbJF9HePAOlk"
      },
      "source": [
        "!rm -f -r ./data\n",
        "!rm -f -r ./models\n",
        "!rm -f -r ./__MACOSX\n",
        "!rm -f ./constants.cc\n",
        "!rm -f ./data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bYQeJNzjtBP"
      },
      "source": [
        "#file paths\n",
        "\n",
        "training_data_path = \"./training_data\"\n",
        "unseen_data_path = \"./unseen_data\"\n",
        "output_path = \"./constants.cc\"\n",
        "\n",
        "base_path = \"./\"\n",
        "\n",
        "MODELS_DIR = base_path+'models/'\n",
        "if not os.path.exists(MODELS_DIR):\n",
        "    os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxFr8-cNfFru"
      },
      "source": [
        "!rm -f -r ./__MACOSX\n",
        "!rm -f -r ./training_data\n",
        "!unzip training_data.zip\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GVjv1Rh53S3"
      },
      "source": [
        "!rm -f -r ./__MACOSX\n",
        "!rm -f -r ./unseen_data\n",
        "\n",
        "!unzip unseen_data.zip\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h_GyKjKiJLc"
      },
      "source": [
        "#get data to pd dataframes\n",
        "\n",
        "def find_csv_filenames(path_to_dir, suffix=\".CSV\"):\n",
        "    filenames = []\n",
        "    for sub in os.walk(path_to_dir):\n",
        "        if sub[0] != path_to_dir:\n",
        "          filenames += [sub[0] + \"/\" +\n",
        "          filename for filename in os.listdir(sub[0]) if filename.endswith(suffix)]\n",
        "    filenames.sort()\n",
        "    return filenames\n",
        "\n",
        "\n",
        "def to_dataframes (data_files):\n",
        "  count = 0\n",
        "\n",
        "  data_frames = []\n",
        "\n",
        "  for data_file in data_files:\n",
        "    \n",
        "        df = pd.read_csv(data_file)\n",
        "        data_frames.append(df)\n",
        "        count += 1\n",
        "        progress = round(count/len(data_files), ndigits=2)\n",
        "        if count % 100 == 0 : \n",
        "          clear_output()\n",
        "          print(\"progress: \"+str(progress))\n",
        "\n",
        "  return data_frames\n",
        "\n",
        "#most common services in selected environments\n",
        "services = [\t\"0af0\", \"1802\", \"180f\", \"1812\", \"1826\", \"2222\", \"ec88\", \"fd5a\",\n",
        "    \"fd6f\", \"fdd2\", \"fddf\", \"fe03\", \"fe07\", \"fe0f\", \"fe61\", \"fe9f\",\n",
        "    \"fea0\", \"feb9\", \"febe\", \"fee0\", \"ff0d\", \"ffc0\", \"ffe0\"]\n",
        "\n",
        "def process_files(data_frames, without_services = False, only_labels = None, remove_columns = [\" services\", \" manufacturer_data_lengths\"]):\n",
        "\n",
        "  input = []\n",
        "  output = []\n",
        "\n",
        "  count = 0\n",
        "  data_columns = []\n",
        "\n",
        "  for df in data_frames:\n",
        "\n",
        "      count+=1\n",
        "  \n",
        "      label = df.iloc[0][\"label\"]\n",
        "\n",
        "      if not only_labels or label in only_labels:\n",
        "        if without_services:\n",
        "          for serv in services:\n",
        "            del df[\" \"+serv]\n",
        "\n",
        "        del df[\"label\"]\n",
        "\n",
        "        #features used for testing that are still in some data samples\n",
        "        for column in remove_columns:\n",
        "          if column in df.columns:\n",
        "            del df[column]\n",
        "\n",
        "\n",
        "        if count == 1:\n",
        "          data_columns = [c.strip() for c in df.columns.values.tolist()]\n",
        "\n",
        "        arr = df.to_numpy().flatten().tolist()\n",
        "\n",
        "        input.append(arr)\n",
        "        output.append(label)\n",
        "\n",
        "  labels_dict = {}\n",
        "\n",
        "  for l in output:\n",
        "      if l not in labels_dict:\n",
        "          labels_dict[l] = 0\n",
        "      labels_dict[l] += 1\n",
        "\n",
        "\n",
        "  print(labels_dict)\n",
        "\n",
        "  labels = list(labels_dict.keys())\n",
        "\n",
        "  return input, output, labels, data_columns\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbcbSdf3o-uK"
      },
      "source": [
        "#normalization\n",
        "\n",
        "def get_normalization_params(X, rows = 5):\n",
        "  mean_list = []\n",
        "  std_list = []\n",
        "\n",
        "  parameters = len(X[0])//rows\n",
        "\n",
        "  for j in range(0, parameters):\n",
        "      mean_sum = 0\n",
        "      for i in range(0, len(X)):\n",
        "          for k in range (0, rows):\n",
        "            mean_sum += X[i][k*parameters+j]\n",
        "      mean = mean_sum/(len(X)*rows)\n",
        "      std_sum = 0\n",
        "      for i in range(0, len(X)):\n",
        "          for k in range (0, rows):\n",
        "            std_sum += m.pow(X[i][k*parameters+j] - mean, 2)\n",
        "      std = m.sqrt(std_sum/(len(X)*rows-1))\n",
        "\n",
        "      mean_list.append(mean)\n",
        "      std_list.append(std)\n",
        "\n",
        "  return mean_list, std_list\n",
        "\n",
        "\n",
        "def normalize_data(data_x, data_y, means, stds, labels, rows = 5):\n",
        "  data_normalized = copy.deepcopy(data_x)\n",
        "  labels_num = []\n",
        "  parameters = len(data_x[0])//rows\n",
        "\n",
        "  for i in range(0, parameters):\n",
        "    mean = means[i]\n",
        "    std = stds[i]\n",
        "\n",
        "    if std != 0:\n",
        "      for j in range(0, len(data_x)):\n",
        "          for k in range(0, rows):\n",
        "              data_normalized[j][k*parameters+i] = (data_normalized[j][k*parameters+i]-mean)/std\n",
        "  \n",
        "  for label in data_y:\n",
        "      labels_num.append(labels.index(label))\n",
        "  return data_normalized, labels_num\n",
        "\n",
        "\n",
        "#generate for contants.cc \n",
        "def get_constants_strings(mean_list, std_list, labels):\n",
        "  mean_str = \"const float mean_list[] = {\"\n",
        "\n",
        "  for i in range(0, len(mean_list)):\n",
        "    if i != 0:\n",
        "      mean_str += \", \"\n",
        "    mean_str += str(mean_list[i])\n",
        "    \n",
        "\n",
        "  mean_str += \"};\"\n",
        "  print(mean_str)\n",
        "\n",
        "  std_str = \"const float std_list[] = {\"\n",
        "\n",
        "  for i in range(0, len(std_list)):\n",
        "    if i != 0:\n",
        "      std_str += \", \"\n",
        "    std_str += str(std_list[i])\n",
        "    \n",
        "\n",
        "  std_str += \"};\"\n",
        "\n",
        "  print(std_str)\n",
        "\n",
        "\n",
        "  labels_str = \"const char available_env[][50] = {\"\n",
        "\n",
        "  for i in range(0, len(labels)):\n",
        "    if i != 0:\n",
        "      labels_str += \", \"\n",
        "    labels_str += \"\\\"\"+labels[i]+\"\\\"\"\n",
        "    \n",
        "\n",
        "  labels_str += \"};\"\n",
        "\n",
        "  return mean_str, std_str, labels_str\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5C9xhx1pF3H"
      },
      "source": [
        "#build model with specified architecture and train with given hyperparams\n",
        "\n",
        "\n",
        "def build_model (architecture, train_x, labels, opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)):\n",
        " \n",
        "  model_compile = tf.keras.models.Sequential( \n",
        "      [\n",
        "        tf.keras.layers.Flatten(input_shape=(len(train_x[0]),)),\n",
        "        architecture,\n",
        "        tf.keras.layers.Dense(len(labels), activation='softmax')\n",
        "      ]\n",
        "  )\n",
        "  model_compile.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=tf.keras.metrics.SparseCategoricalAccuracy())\n",
        "\n",
        "  return model_compile\n",
        "\n",
        "def train_model(model_train, train_x, train_y, test_x, test_y, batch_size = 25, epochs = 25):\n",
        "  history = model_train.fit(train_x, train_y, epochs=epochs, validation_data=(test_x, test_y), verbose=0, batch_size=batch_size)\n",
        "\n",
        "  _, test_acc = model_train.evaluate(test_x, test_y, verbose=0)\n",
        "  return history, test_acc\n",
        "\n",
        "def plot_results(history):\n",
        "  # plot loss during training\n",
        "  pyplot.subplot(211)\n",
        "  pyplot.title('Loss')\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  # plot accuracy during training\n",
        "  pyplot.subplot(212)\n",
        "  pyplot.title('Accuracy')\n",
        "  pyplot.plot(history.history['accuracy'], label='train')\n",
        "  pyplot.plot(history.history['val_accuracy'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "\n",
        "def build_layers (option, activation = \"relu\"):\n",
        "    model_layers = tf.keras.models.Sequential()\n",
        "    for o in option:\n",
        "      if isinstance(o, int) and o != 0:\n",
        "        model_layers.add(tf.keras.layers.Dense(o, activation=activation))\n",
        "      elif o != 0:\n",
        "        model_layers.add(tf.keras.layers.Dropout(o))\n",
        "    return model_layers\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQjXv4lup18P"
      },
      "source": [
        "# Convert TensorFlow model to TensorFlow Lite with quantization that is feasible to execute on embedded device \n",
        "    \n",
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "def convert_model(model_to_convert, train_x):\n",
        "  converter = tf.lite.TFLiteConverter.from_keras_model(model_to_convert)\n",
        "  model_no_quant_tflite = converter.convert()\n",
        "\n",
        " \n",
        "  # Convert the model to the TensorFlow Lite format with quantization\n",
        "\n",
        "  # Set the optimization flag.\n",
        "  converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "  # Enforce integer only quantization\n",
        "  converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]\n",
        "  converter.inference_input_type = tf.float32\n",
        "  converter.inference_output_type = tf.float32\n",
        "  # Provide a representative dataset to ensure we quantize correctly.\n",
        "\n",
        "  def representative_dataset():\n",
        "    for i in range(len(train_x)):\n",
        "     yield([np.float32(train_x[i]).reshape(1, len(train_x[0]))])\n",
        "\n",
        "  converter.representative_dataset = representative_dataset\n",
        "  model_tflite = converter.convert()\n",
        "\n",
        "  return model_no_quant_tflite, model_tflite\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvqD2PEE8kYw"
      },
      "source": [
        "#predict and evaluate model\n",
        "\n",
        "def evaluate_preds(predictions, test_x, test_y, labels, data_columns, verbose = True):\n",
        "  wrong_predictions = {label:0 for label in labels}\n",
        "  df_columns = np.array([[c+\"_\"+str(j) for c in data_columns] for j in range(0,5)]).flatten()\n",
        "  evaluation = {label:{label_: pd.DataFrame(index=df_columns, dtype=\"int\").T for label_ in labels} for label in labels}\n",
        "\n",
        "  for i in range(0, len(predictions)):\n",
        "    pred = predictions[i].flatten().tolist()\n",
        "    pred_label = \"\"\n",
        "    pred_index = pred.index( max(pred))\n",
        "    if len(labels) > pred_index:\n",
        "       pred_label = labels[pred_index] \n",
        "    true_label = labels[test_y[i]]\n",
        "\n",
        "    # which environments get wrongly classified to which environments\n",
        "    evaluation[true_label][pred_label]= evaluation[true_label][pred_label].append(pd.DataFrame([int((test_x[i][k] * std_list[k%len(data_columns)]) + mean_list[k%len(data_columns)]) for k in range(0, len(test_x[i]))], index=df_columns, dtype=\"int\").T, ignore_index = True)\n",
        "    if pred_label != true_label:\n",
        "        wrong_predictions[true_label] += 1\n",
        "\n",
        "  w_pred_str = \"\"\n",
        "  for l in wrong_predictions:\n",
        "    w_pred_str += l + \": \"+ str(wrong_predictions[l])+\"/\"+str(len([label_y for label_y in test_y if label_y == labels.index(l)]))+\", \"\n",
        "\n",
        "  accuracy = 1- sum(wrong_predictions.values())/len(test_y)\n",
        "\n",
        "  if verbose: \n",
        "    print(\"predicted wrong: \"+w_pred_str)\n",
        "    print(\"predicted wrong overall: \"+str(sum(wrong_predictions.values()))+\"/\"+str(len(test_y))+\" (acc: \"+str(round(accuracy*100,2))+\"%)\")\n",
        "  \n",
        "  return evaluation, accuracy\n",
        "\n",
        "\n",
        "\n",
        "def predict_tflite(tflite_model, test_x):\n",
        "  # Prepare the test data\n",
        "  x_test_ = test_x.copy()\n",
        "  x_test_ = x_test_.astype(np.float32)\n",
        "\n",
        " \n",
        "  # Initialize the TFLite interpreter\n",
        "  interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "  interpreter.allocate_tensors()\n",
        "\n",
        "  input_details = interpreter.get_input_details()[0]\n",
        "  output_details = interpreter.get_output_details()[0]\n",
        "\n",
        "  # Invoke the interpreter\n",
        "  y_pred = []\n",
        "  for i in range((len(x_test_))):\n",
        "    interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
        "    interpreter.invoke()\n",
        "    y_pred.append(interpreter.get_tensor(output_details[\"index\"]))\n",
        "    \n",
        "  \n",
        "\n",
        "  return y_pred\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgjuyXAE1EGs"
      },
      "source": [
        "#export model to constants.cc \n",
        "\n",
        "def export_model(mean_str, std_str, labels_str, verbose = True):\n",
        "  # Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
        "  !xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "  REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "  !sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}\n",
        "\n",
        "  if verbose:\n",
        "    clear_output()\n",
        "\n",
        "  !rm -f ./constants.cc\n",
        "\n",
        "  model_str = \"alignas(16) const unsigned char g_modelurd[] = \"\n",
        "  with open(MODEL_TFLITE_MICRO, 'r') as file:\n",
        "      data = file.read();\n",
        "      model_str += data[data.index(\"{\"): len(data)].replace(\"unsigned\", \"const\")\n",
        "\n",
        "  output_str = \"\"\n",
        "  output_str += \"#include \\\"constants.h\\\"\\n\"\n",
        "  output_str += mean_str +\"\\n\"\n",
        "  output_str += std_str + \"\\n\"\n",
        "  output_str += labels_str + \"\\n\"\n",
        "  output_str += \"const int available_env_len = \"+str(len(labels)) +\";\\n\"\n",
        "  output_str += model_str\n",
        "\n",
        "  with open(output_path, \"w\") as file:\n",
        "    file.write(output_str)\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXY_So0A3iqU",
        "outputId": "d08b021e-2395-47ef-e601-6897d878620d"
      },
      "source": [
        "#get data sets\n",
        "train_data_frames = to_dataframes(find_csv_filenames(training_data_path))\n",
        "test_data_frames = to_dataframes(find_csv_filenames(unseen_data_path))\n",
        "\n",
        "print(len(train_data_frames))\n",
        "print(len(test_data_frames))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "progress: 0.98\n",
            "12098\n",
            "3555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjViGQPN3hy6",
        "outputId": "7d335fa3-3804-4ab5-898d-cd5679729d89"
      },
      "source": [
        "#preperation main data set\n",
        "\n",
        "data_x, data_y, labels, parameters = process_files(copy.deepcopy(train_data_frames))\n",
        "\n",
        "mean_list, std_list = get_normalization_params(X= data_x)\n",
        "mean_str, std_str,labels_str = get_constants_strings(mean_list= mean_list, std_list= std_list, labels=labels)\n",
        "X, y_num = normalize_data(data_x=data_x, data_y=data_y, means=mean_list, stds=std_list, labels = labels)\n",
        "\n",
        "print(parameters)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'street': 1189, 'park': 877, 'apartment': 1550, 'supermarket': 1495, 'clothing_store': 1315, 'train': 802, 'bus': 1123, 'gym': 350, 'car': 598, 'house': 1150, 'nature': 445, 'restaurant': 500, 'cinema': 200, 'concert': 104, 'plane': 200, 'bar': 200}\n",
            "const float mean_list[] = {31.44268474127955, 4.7901636634154405, 4.803636964787568, 2.092759133741114, 9.539709042816995, 90.03927921970573, 12.839180029756985, 6.282740948917176, 50.077186311787074, 147.01858158373284, 91.59257728550173, 14.267416101835014, 10.387716978012895, 2.510233096379567, 42.05886923458423, -72.64306496941643, -86.04589188295586, -46.72296247313606, -88.2988262522731, -41.97154901636634, 7.626070424863614, 9475.404380889404, 63560.128616300215, 0.05733179037857497, -0.5648867581418416, 93268.30338898991, -0.5216234088279055, 93272.18146801124, -0.5667548355100016, 93276.25233922963, -0.5651347330137213, 93287.50385187635, -0.5569846255579435, 93283.89424698298, -0.49244503223673336, 93287.953529509, -0.5176558108778311, 93291.80094230452, -0.41844933046784594, 93295.22965779468, -0.5595966275417424, 93298.92684741279, -0.4686559761944123, 93302.50595139693, -0.5666225822449992, 93306.24785915027};\n",
            "const float std_list[] = {32.675922508563275, 7.360827238515185, 7.394363547623756, 1.3667302838922368, 10.862104081542073, 86.49791144931037, 11.573231353625836, 12.108659627575914, 77.4729697771597, 120.20582643997535, 41.77486424433961, 3.3112901987423444, 4.355003772334171, 8.104924279616943, 30.31339809331407, 9.50736530988305, 10.691162577903212, 10.12595167570739, 9.143135421519549, 9.972436376148506, 2.9556254805912134, 2962.924698116494, 14261.784773427273, 0.2586650194856517, 6.826397978433112, 1312756.0422811015, 6.805179883933502, 1312796.672835736, 6.821694652245459, 1312837.3947754998, 6.8236633181926525, 1312874.9092448764, 6.82847100267021, 1312913.7654835028, 6.851363380470295, 1312950.731601689, 6.844128697713389, 1312992.023277002, 6.86755096840121, 1313027.8199529452, 6.828167858999585, 1313063.271165659, 6.8356903259041255, 1313102.2562044812, 6.844926207011351, 1313137.5130377077};\n",
            "['device_count', 'lost_devices', 'new_devices', 'different_services', 'services_count', 'txpower_count', 'tx_power_avg', 'min_txpower', 'max_txpower', 'man_packet_len_count', 'manufacturer_data_lengths_sum', 'manufacturer_data_len_avg', 'avg_received', 'min_received', 'max_received', 'avg_avg_rssi', 'min_avg_rssi', 'max_avg_rssi', 'min_rssi', 'max_rssi', 'avg_rssi_difference', 'avg_avg_difference_between_beacons', 'avg_difference_first_last', '0af0', '1802', '180f', '1812', '1826', '2222', 'ec88', 'fd5a', 'fd6f', 'fdd2', 'fddf', 'fe03', 'fe07', 'fe0f', 'fe61', 'fe9f', 'fea0', 'feb9', 'febe', 'fee0', 'ff0d', 'ffc0', 'ffe0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FB0K1986AkQ",
        "outputId": "cb4d8000-40cc-4538-ec19-6b20b525582c"
      },
      "source": [
        "#preperation unseen data set\n",
        "\n",
        "test_data_x, test_data_y, _, _ = process_files(copy.deepcopy(test_data_frames), only_labels = labels)\n",
        "\n",
        "test_X, test_y_num = normalize_data(data_x=test_data_x, data_y=test_data_y, means=mean_list, stds=std_list, labels= labels)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'supermarket': 710, 'bus': 507, 'street': 611, 'park': 300, 'clothing_store': 426, 'house': 101, 'train': 100, 'car': 250, 'restaurant': 250, 'nature': 200, 'apartment': 100}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xp8j8IEZUui8",
        "outputId": "f12b620d-cd69-4173-dc03-0c98b8ee1034"
      },
      "source": [
        "#generate configurations to evaluate \n",
        "\n",
        "diff_layer_count = [2,3,4]\n",
        "diff_layers = [25, 50, 100, 250, 300]\n",
        "diff_dropouts = [0.1]#[0, 0.05, 0.1, 0.2]\n",
        "diff_test_sizes = [0.1,0.2, 0.25, 0.3, 0.4,0.5]\n",
        "diff_epochs = [25, 50, 75, 100]\n",
        "diff_batch_sizes = [10, 25, 50, 100]\n",
        "times = 3\n",
        "\n",
        "\n",
        "def build_options (factor, start_list, result):\n",
        "  if factor == 0:\n",
        "    return result\n",
        "  return build_options(factor-1, start_list, [option + [item] for item in start_list for option in result])\n",
        "\n",
        "\n",
        "architectures_multiple = [item for sublist in [build_options(count-1, diff_layers, [[l, d] for l in diff_layers for d in diff_dropouts]) for count in diff_layer_count] for item in sublist]\n",
        "\n",
        "option = [250, 0, 250]\n",
        "architectures_single = [[option[0], d, option[2]] for d in diff_dropouts]\n",
        "\n",
        "architectures = architectures_multiple\n",
        "\n",
        "print(len(architectures))\n",
        "print(architectures)\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "775\n",
            "[[25, 0.1, 25], [50, 0.1, 25], [100, 0.1, 25], [250, 0.1, 25], [300, 0.1, 25], [25, 0.1, 50], [50, 0.1, 50], [100, 0.1, 50], [250, 0.1, 50], [300, 0.1, 50], [25, 0.1, 100], [50, 0.1, 100], [100, 0.1, 100], [250, 0.1, 100], [300, 0.1, 100], [25, 0.1, 250], [50, 0.1, 250], [100, 0.1, 250], [250, 0.1, 250], [300, 0.1, 250], [25, 0.1, 300], [50, 0.1, 300], [100, 0.1, 300], [250, 0.1, 300], [300, 0.1, 300], [25, 0.1, 25, 25], [50, 0.1, 25, 25], [100, 0.1, 25, 25], [250, 0.1, 25, 25], [300, 0.1, 25, 25], [25, 0.1, 50, 25], [50, 0.1, 50, 25], [100, 0.1, 50, 25], [250, 0.1, 50, 25], [300, 0.1, 50, 25], [25, 0.1, 100, 25], [50, 0.1, 100, 25], [100, 0.1, 100, 25], [250, 0.1, 100, 25], [300, 0.1, 100, 25], [25, 0.1, 250, 25], [50, 0.1, 250, 25], [100, 0.1, 250, 25], [250, 0.1, 250, 25], [300, 0.1, 250, 25], [25, 0.1, 300, 25], [50, 0.1, 300, 25], [100, 0.1, 300, 25], [250, 0.1, 300, 25], [300, 0.1, 300, 25], [25, 0.1, 25, 50], [50, 0.1, 25, 50], [100, 0.1, 25, 50], [250, 0.1, 25, 50], [300, 0.1, 25, 50], [25, 0.1, 50, 50], [50, 0.1, 50, 50], [100, 0.1, 50, 50], [250, 0.1, 50, 50], [300, 0.1, 50, 50], [25, 0.1, 100, 50], [50, 0.1, 100, 50], [100, 0.1, 100, 50], [250, 0.1, 100, 50], [300, 0.1, 100, 50], [25, 0.1, 250, 50], [50, 0.1, 250, 50], [100, 0.1, 250, 50], [250, 0.1, 250, 50], [300, 0.1, 250, 50], [25, 0.1, 300, 50], [50, 0.1, 300, 50], [100, 0.1, 300, 50], [250, 0.1, 300, 50], [300, 0.1, 300, 50], [25, 0.1, 25, 100], [50, 0.1, 25, 100], [100, 0.1, 25, 100], [250, 0.1, 25, 100], [300, 0.1, 25, 100], [25, 0.1, 50, 100], [50, 0.1, 50, 100], [100, 0.1, 50, 100], [250, 0.1, 50, 100], [300, 0.1, 50, 100], [25, 0.1, 100, 100], [50, 0.1, 100, 100], [100, 0.1, 100, 100], [250, 0.1, 100, 100], [300, 0.1, 100, 100], [25, 0.1, 250, 100], [50, 0.1, 250, 100], [100, 0.1, 250, 100], [250, 0.1, 250, 100], [300, 0.1, 250, 100], [25, 0.1, 300, 100], [50, 0.1, 300, 100], [100, 0.1, 300, 100], [250, 0.1, 300, 100], [300, 0.1, 300, 100], [25, 0.1, 25, 250], [50, 0.1, 25, 250], [100, 0.1, 25, 250], [250, 0.1, 25, 250], [300, 0.1, 25, 250], [25, 0.1, 50, 250], [50, 0.1, 50, 250], [100, 0.1, 50, 250], [250, 0.1, 50, 250], [300, 0.1, 50, 250], [25, 0.1, 100, 250], [50, 0.1, 100, 250], [100, 0.1, 100, 250], [250, 0.1, 100, 250], [300, 0.1, 100, 250], [25, 0.1, 250, 250], [50, 0.1, 250, 250], [100, 0.1, 250, 250], [250, 0.1, 250, 250], [300, 0.1, 250, 250], [25, 0.1, 300, 250], [50, 0.1, 300, 250], [100, 0.1, 300, 250], [250, 0.1, 300, 250], [300, 0.1, 300, 250], [25, 0.1, 25, 300], [50, 0.1, 25, 300], [100, 0.1, 25, 300], [250, 0.1, 25, 300], [300, 0.1, 25, 300], [25, 0.1, 50, 300], [50, 0.1, 50, 300], [100, 0.1, 50, 300], [250, 0.1, 50, 300], [300, 0.1, 50, 300], [25, 0.1, 100, 300], [50, 0.1, 100, 300], [100, 0.1, 100, 300], [250, 0.1, 100, 300], [300, 0.1, 100, 300], [25, 0.1, 250, 300], [50, 0.1, 250, 300], [100, 0.1, 250, 300], [250, 0.1, 250, 300], [300, 0.1, 250, 300], [25, 0.1, 300, 300], [50, 0.1, 300, 300], [100, 0.1, 300, 300], [250, 0.1, 300, 300], [300, 0.1, 300, 300], [25, 0.1, 25, 25, 25], [50, 0.1, 25, 25, 25], [100, 0.1, 25, 25, 25], [250, 0.1, 25, 25, 25], [300, 0.1, 25, 25, 25], [25, 0.1, 50, 25, 25], [50, 0.1, 50, 25, 25], [100, 0.1, 50, 25, 25], [250, 0.1, 50, 25, 25], [300, 0.1, 50, 25, 25], [25, 0.1, 100, 25, 25], [50, 0.1, 100, 25, 25], [100, 0.1, 100, 25, 25], [250, 0.1, 100, 25, 25], [300, 0.1, 100, 25, 25], [25, 0.1, 250, 25, 25], [50, 0.1, 250, 25, 25], [100, 0.1, 250, 25, 25], [250, 0.1, 250, 25, 25], [300, 0.1, 250, 25, 25], [25, 0.1, 300, 25, 25], [50, 0.1, 300, 25, 25], [100, 0.1, 300, 25, 25], [250, 0.1, 300, 25, 25], [300, 0.1, 300, 25, 25], [25, 0.1, 25, 50, 25], [50, 0.1, 25, 50, 25], [100, 0.1, 25, 50, 25], [250, 0.1, 25, 50, 25], [300, 0.1, 25, 50, 25], [25, 0.1, 50, 50, 25], [50, 0.1, 50, 50, 25], [100, 0.1, 50, 50, 25], [250, 0.1, 50, 50, 25], [300, 0.1, 50, 50, 25], [25, 0.1, 100, 50, 25], [50, 0.1, 100, 50, 25], [100, 0.1, 100, 50, 25], [250, 0.1, 100, 50, 25], [300, 0.1, 100, 50, 25], [25, 0.1, 250, 50, 25], [50, 0.1, 250, 50, 25], [100, 0.1, 250, 50, 25], [250, 0.1, 250, 50, 25], [300, 0.1, 250, 50, 25], [25, 0.1, 300, 50, 25], [50, 0.1, 300, 50, 25], [100, 0.1, 300, 50, 25], [250, 0.1, 300, 50, 25], [300, 0.1, 300, 50, 25], [25, 0.1, 25, 100, 25], [50, 0.1, 25, 100, 25], [100, 0.1, 25, 100, 25], [250, 0.1, 25, 100, 25], [300, 0.1, 25, 100, 25], [25, 0.1, 50, 100, 25], [50, 0.1, 50, 100, 25], [100, 0.1, 50, 100, 25], [250, 0.1, 50, 100, 25], [300, 0.1, 50, 100, 25], [25, 0.1, 100, 100, 25], [50, 0.1, 100, 100, 25], [100, 0.1, 100, 100, 25], [250, 0.1, 100, 100, 25], [300, 0.1, 100, 100, 25], [25, 0.1, 250, 100, 25], [50, 0.1, 250, 100, 25], [100, 0.1, 250, 100, 25], [250, 0.1, 250, 100, 25], [300, 0.1, 250, 100, 25], [25, 0.1, 300, 100, 25], [50, 0.1, 300, 100, 25], [100, 0.1, 300, 100, 25], [250, 0.1, 300, 100, 25], [300, 0.1, 300, 100, 25], [25, 0.1, 25, 250, 25], [50, 0.1, 25, 250, 25], [100, 0.1, 25, 250, 25], [250, 0.1, 25, 250, 25], [300, 0.1, 25, 250, 25], [25, 0.1, 50, 250, 25], [50, 0.1, 50, 250, 25], [100, 0.1, 50, 250, 25], [250, 0.1, 50, 250, 25], [300, 0.1, 50, 250, 25], [25, 0.1, 100, 250, 25], [50, 0.1, 100, 250, 25], [100, 0.1, 100, 250, 25], [250, 0.1, 100, 250, 25], [300, 0.1, 100, 250, 25], [25, 0.1, 250, 250, 25], [50, 0.1, 250, 250, 25], [100, 0.1, 250, 250, 25], [250, 0.1, 250, 250, 25], [300, 0.1, 250, 250, 25], [25, 0.1, 300, 250, 25], [50, 0.1, 300, 250, 25], [100, 0.1, 300, 250, 25], [250, 0.1, 300, 250, 25], [300, 0.1, 300, 250, 25], [25, 0.1, 25, 300, 25], [50, 0.1, 25, 300, 25], [100, 0.1, 25, 300, 25], [250, 0.1, 25, 300, 25], [300, 0.1, 25, 300, 25], [25, 0.1, 50, 300, 25], [50, 0.1, 50, 300, 25], [100, 0.1, 50, 300, 25], [250, 0.1, 50, 300, 25], [300, 0.1, 50, 300, 25], [25, 0.1, 100, 300, 25], [50, 0.1, 100, 300, 25], [100, 0.1, 100, 300, 25], [250, 0.1, 100, 300, 25], [300, 0.1, 100, 300, 25], [25, 0.1, 250, 300, 25], [50, 0.1, 250, 300, 25], [100, 0.1, 250, 300, 25], [250, 0.1, 250, 300, 25], [300, 0.1, 250, 300, 25], [25, 0.1, 300, 300, 25], [50, 0.1, 300, 300, 25], [100, 0.1, 300, 300, 25], [250, 0.1, 300, 300, 25], [300, 0.1, 300, 300, 25], [25, 0.1, 25, 25, 50], [50, 0.1, 25, 25, 50], [100, 0.1, 25, 25, 50], [250, 0.1, 25, 25, 50], [300, 0.1, 25, 25, 50], [25, 0.1, 50, 25, 50], [50, 0.1, 50, 25, 50], [100, 0.1, 50, 25, 50], [250, 0.1, 50, 25, 50], [300, 0.1, 50, 25, 50], [25, 0.1, 100, 25, 50], [50, 0.1, 100, 25, 50], [100, 0.1, 100, 25, 50], [250, 0.1, 100, 25, 50], [300, 0.1, 100, 25, 50], [25, 0.1, 250, 25, 50], [50, 0.1, 250, 25, 50], [100, 0.1, 250, 25, 50], [250, 0.1, 250, 25, 50], [300, 0.1, 250, 25, 50], [25, 0.1, 300, 25, 50], [50, 0.1, 300, 25, 50], [100, 0.1, 300, 25, 50], [250, 0.1, 300, 25, 50], [300, 0.1, 300, 25, 50], [25, 0.1, 25, 50, 50], [50, 0.1, 25, 50, 50], [100, 0.1, 25, 50, 50], [250, 0.1, 25, 50, 50], [300, 0.1, 25, 50, 50], [25, 0.1, 50, 50, 50], [50, 0.1, 50, 50, 50], [100, 0.1, 50, 50, 50], [250, 0.1, 50, 50, 50], [300, 0.1, 50, 50, 50], [25, 0.1, 100, 50, 50], [50, 0.1, 100, 50, 50], [100, 0.1, 100, 50, 50], [250, 0.1, 100, 50, 50], [300, 0.1, 100, 50, 50], [25, 0.1, 250, 50, 50], [50, 0.1, 250, 50, 50], [100, 0.1, 250, 50, 50], [250, 0.1, 250, 50, 50], [300, 0.1, 250, 50, 50], [25, 0.1, 300, 50, 50], [50, 0.1, 300, 50, 50], [100, 0.1, 300, 50, 50], [250, 0.1, 300, 50, 50], [300, 0.1, 300, 50, 50], [25, 0.1, 25, 100, 50], [50, 0.1, 25, 100, 50], [100, 0.1, 25, 100, 50], [250, 0.1, 25, 100, 50], [300, 0.1, 25, 100, 50], [25, 0.1, 50, 100, 50], [50, 0.1, 50, 100, 50], [100, 0.1, 50, 100, 50], [250, 0.1, 50, 100, 50], [300, 0.1, 50, 100, 50], [25, 0.1, 100, 100, 50], [50, 0.1, 100, 100, 50], [100, 0.1, 100, 100, 50], [250, 0.1, 100, 100, 50], [300, 0.1, 100, 100, 50], [25, 0.1, 250, 100, 50], [50, 0.1, 250, 100, 50], [100, 0.1, 250, 100, 50], [250, 0.1, 250, 100, 50], [300, 0.1, 250, 100, 50], [25, 0.1, 300, 100, 50], [50, 0.1, 300, 100, 50], [100, 0.1, 300, 100, 50], [250, 0.1, 300, 100, 50], [300, 0.1, 300, 100, 50], [25, 0.1, 25, 250, 50], [50, 0.1, 25, 250, 50], [100, 0.1, 25, 250, 50], [250, 0.1, 25, 250, 50], [300, 0.1, 25, 250, 50], [25, 0.1, 50, 250, 50], [50, 0.1, 50, 250, 50], [100, 0.1, 50, 250, 50], [250, 0.1, 50, 250, 50], [300, 0.1, 50, 250, 50], [25, 0.1, 100, 250, 50], [50, 0.1, 100, 250, 50], [100, 0.1, 100, 250, 50], [250, 0.1, 100, 250, 50], [300, 0.1, 100, 250, 50], [25, 0.1, 250, 250, 50], [50, 0.1, 250, 250, 50], [100, 0.1, 250, 250, 50], [250, 0.1, 250, 250, 50], [300, 0.1, 250, 250, 50], [25, 0.1, 300, 250, 50], [50, 0.1, 300, 250, 50], [100, 0.1, 300, 250, 50], [250, 0.1, 300, 250, 50], [300, 0.1, 300, 250, 50], [25, 0.1, 25, 300, 50], [50, 0.1, 25, 300, 50], [100, 0.1, 25, 300, 50], [250, 0.1, 25, 300, 50], [300, 0.1, 25, 300, 50], [25, 0.1, 50, 300, 50], [50, 0.1, 50, 300, 50], [100, 0.1, 50, 300, 50], [250, 0.1, 50, 300, 50], [300, 0.1, 50, 300, 50], [25, 0.1, 100, 300, 50], [50, 0.1, 100, 300, 50], [100, 0.1, 100, 300, 50], [250, 0.1, 100, 300, 50], [300, 0.1, 100, 300, 50], [25, 0.1, 250, 300, 50], [50, 0.1, 250, 300, 50], [100, 0.1, 250, 300, 50], [250, 0.1, 250, 300, 50], [300, 0.1, 250, 300, 50], [25, 0.1, 300, 300, 50], [50, 0.1, 300, 300, 50], [100, 0.1, 300, 300, 50], [250, 0.1, 300, 300, 50], [300, 0.1, 300, 300, 50], [25, 0.1, 25, 25, 100], [50, 0.1, 25, 25, 100], [100, 0.1, 25, 25, 100], [250, 0.1, 25, 25, 100], [300, 0.1, 25, 25, 100], [25, 0.1, 50, 25, 100], [50, 0.1, 50, 25, 100], [100, 0.1, 50, 25, 100], [250, 0.1, 50, 25, 100], [300, 0.1, 50, 25, 100], [25, 0.1, 100, 25, 100], [50, 0.1, 100, 25, 100], [100, 0.1, 100, 25, 100], [250, 0.1, 100, 25, 100], [300, 0.1, 100, 25, 100], [25, 0.1, 250, 25, 100], [50, 0.1, 250, 25, 100], [100, 0.1, 250, 25, 100], [250, 0.1, 250, 25, 100], [300, 0.1, 250, 25, 100], [25, 0.1, 300, 25, 100], [50, 0.1, 300, 25, 100], [100, 0.1, 300, 25, 100], [250, 0.1, 300, 25, 100], [300, 0.1, 300, 25, 100], [25, 0.1, 25, 50, 100], [50, 0.1, 25, 50, 100], [100, 0.1, 25, 50, 100], [250, 0.1, 25, 50, 100], [300, 0.1, 25, 50, 100], [25, 0.1, 50, 50, 100], [50, 0.1, 50, 50, 100], [100, 0.1, 50, 50, 100], [250, 0.1, 50, 50, 100], [300, 0.1, 50, 50, 100], [25, 0.1, 100, 50, 100], [50, 0.1, 100, 50, 100], [100, 0.1, 100, 50, 100], [250, 0.1, 100, 50, 100], [300, 0.1, 100, 50, 100], [25, 0.1, 250, 50, 100], [50, 0.1, 250, 50, 100], [100, 0.1, 250, 50, 100], [250, 0.1, 250, 50, 100], [300, 0.1, 250, 50, 100], [25, 0.1, 300, 50, 100], [50, 0.1, 300, 50, 100], [100, 0.1, 300, 50, 100], [250, 0.1, 300, 50, 100], [300, 0.1, 300, 50, 100], [25, 0.1, 25, 100, 100], [50, 0.1, 25, 100, 100], [100, 0.1, 25, 100, 100], [250, 0.1, 25, 100, 100], [300, 0.1, 25, 100, 100], [25, 0.1, 50, 100, 100], [50, 0.1, 50, 100, 100], [100, 0.1, 50, 100, 100], [250, 0.1, 50, 100, 100], [300, 0.1, 50, 100, 100], [25, 0.1, 100, 100, 100], [50, 0.1, 100, 100, 100], [100, 0.1, 100, 100, 100], [250, 0.1, 100, 100, 100], [300, 0.1, 100, 100, 100], [25, 0.1, 250, 100, 100], [50, 0.1, 250, 100, 100], [100, 0.1, 250, 100, 100], [250, 0.1, 250, 100, 100], [300, 0.1, 250, 100, 100], [25, 0.1, 300, 100, 100], [50, 0.1, 300, 100, 100], [100, 0.1, 300, 100, 100], [250, 0.1, 300, 100, 100], [300, 0.1, 300, 100, 100], [25, 0.1, 25, 250, 100], [50, 0.1, 25, 250, 100], [100, 0.1, 25, 250, 100], [250, 0.1, 25, 250, 100], [300, 0.1, 25, 250, 100], [25, 0.1, 50, 250, 100], [50, 0.1, 50, 250, 100], [100, 0.1, 50, 250, 100], [250, 0.1, 50, 250, 100], [300, 0.1, 50, 250, 100], [25, 0.1, 100, 250, 100], [50, 0.1, 100, 250, 100], [100, 0.1, 100, 250, 100], [250, 0.1, 100, 250, 100], [300, 0.1, 100, 250, 100], [25, 0.1, 250, 250, 100], [50, 0.1, 250, 250, 100], [100, 0.1, 250, 250, 100], [250, 0.1, 250, 250, 100], [300, 0.1, 250, 250, 100], [25, 0.1, 300, 250, 100], [50, 0.1, 300, 250, 100], [100, 0.1, 300, 250, 100], [250, 0.1, 300, 250, 100], [300, 0.1, 300, 250, 100], [25, 0.1, 25, 300, 100], [50, 0.1, 25, 300, 100], [100, 0.1, 25, 300, 100], [250, 0.1, 25, 300, 100], [300, 0.1, 25, 300, 100], [25, 0.1, 50, 300, 100], [50, 0.1, 50, 300, 100], [100, 0.1, 50, 300, 100], [250, 0.1, 50, 300, 100], [300, 0.1, 50, 300, 100], [25, 0.1, 100, 300, 100], [50, 0.1, 100, 300, 100], [100, 0.1, 100, 300, 100], [250, 0.1, 100, 300, 100], [300, 0.1, 100, 300, 100], [25, 0.1, 250, 300, 100], [50, 0.1, 250, 300, 100], [100, 0.1, 250, 300, 100], [250, 0.1, 250, 300, 100], [300, 0.1, 250, 300, 100], [25, 0.1, 300, 300, 100], [50, 0.1, 300, 300, 100], [100, 0.1, 300, 300, 100], [250, 0.1, 300, 300, 100], [300, 0.1, 300, 300, 100], [25, 0.1, 25, 25, 250], [50, 0.1, 25, 25, 250], [100, 0.1, 25, 25, 250], [250, 0.1, 25, 25, 250], [300, 0.1, 25, 25, 250], [25, 0.1, 50, 25, 250], [50, 0.1, 50, 25, 250], [100, 0.1, 50, 25, 250], [250, 0.1, 50, 25, 250], [300, 0.1, 50, 25, 250], [25, 0.1, 100, 25, 250], [50, 0.1, 100, 25, 250], [100, 0.1, 100, 25, 250], [250, 0.1, 100, 25, 250], [300, 0.1, 100, 25, 250], [25, 0.1, 250, 25, 250], [50, 0.1, 250, 25, 250], [100, 0.1, 250, 25, 250], [250, 0.1, 250, 25, 250], [300, 0.1, 250, 25, 250], [25, 0.1, 300, 25, 250], [50, 0.1, 300, 25, 250], [100, 0.1, 300, 25, 250], [250, 0.1, 300, 25, 250], [300, 0.1, 300, 25, 250], [25, 0.1, 25, 50, 250], [50, 0.1, 25, 50, 250], [100, 0.1, 25, 50, 250], [250, 0.1, 25, 50, 250], [300, 0.1, 25, 50, 250], [25, 0.1, 50, 50, 250], [50, 0.1, 50, 50, 250], [100, 0.1, 50, 50, 250], [250, 0.1, 50, 50, 250], [300, 0.1, 50, 50, 250], [25, 0.1, 100, 50, 250], [50, 0.1, 100, 50, 250], [100, 0.1, 100, 50, 250], [250, 0.1, 100, 50, 250], [300, 0.1, 100, 50, 250], [25, 0.1, 250, 50, 250], [50, 0.1, 250, 50, 250], [100, 0.1, 250, 50, 250], [250, 0.1, 250, 50, 250], [300, 0.1, 250, 50, 250], [25, 0.1, 300, 50, 250], [50, 0.1, 300, 50, 250], [100, 0.1, 300, 50, 250], [250, 0.1, 300, 50, 250], [300, 0.1, 300, 50, 250], [25, 0.1, 25, 100, 250], [50, 0.1, 25, 100, 250], [100, 0.1, 25, 100, 250], [250, 0.1, 25, 100, 250], [300, 0.1, 25, 100, 250], [25, 0.1, 50, 100, 250], [50, 0.1, 50, 100, 250], [100, 0.1, 50, 100, 250], [250, 0.1, 50, 100, 250], [300, 0.1, 50, 100, 250], [25, 0.1, 100, 100, 250], [50, 0.1, 100, 100, 250], [100, 0.1, 100, 100, 250], [250, 0.1, 100, 100, 250], [300, 0.1, 100, 100, 250], [25, 0.1, 250, 100, 250], [50, 0.1, 250, 100, 250], [100, 0.1, 250, 100, 250], [250, 0.1, 250, 100, 250], [300, 0.1, 250, 100, 250], [25, 0.1, 300, 100, 250], [50, 0.1, 300, 100, 250], [100, 0.1, 300, 100, 250], [250, 0.1, 300, 100, 250], [300, 0.1, 300, 100, 250], [25, 0.1, 25, 250, 250], [50, 0.1, 25, 250, 250], [100, 0.1, 25, 250, 250], [250, 0.1, 25, 250, 250], [300, 0.1, 25, 250, 250], [25, 0.1, 50, 250, 250], [50, 0.1, 50, 250, 250], [100, 0.1, 50, 250, 250], [250, 0.1, 50, 250, 250], [300, 0.1, 50, 250, 250], [25, 0.1, 100, 250, 250], [50, 0.1, 100, 250, 250], [100, 0.1, 100, 250, 250], [250, 0.1, 100, 250, 250], [300, 0.1, 100, 250, 250], [25, 0.1, 250, 250, 250], [50, 0.1, 250, 250, 250], [100, 0.1, 250, 250, 250], [250, 0.1, 250, 250, 250], [300, 0.1, 250, 250, 250], [25, 0.1, 300, 250, 250], [50, 0.1, 300, 250, 250], [100, 0.1, 300, 250, 250], [250, 0.1, 300, 250, 250], [300, 0.1, 300, 250, 250], [25, 0.1, 25, 300, 250], [50, 0.1, 25, 300, 250], [100, 0.1, 25, 300, 250], [250, 0.1, 25, 300, 250], [300, 0.1, 25, 300, 250], [25, 0.1, 50, 300, 250], [50, 0.1, 50, 300, 250], [100, 0.1, 50, 300, 250], [250, 0.1, 50, 300, 250], [300, 0.1, 50, 300, 250], [25, 0.1, 100, 300, 250], [50, 0.1, 100, 300, 250], [100, 0.1, 100, 300, 250], [250, 0.1, 100, 300, 250], [300, 0.1, 100, 300, 250], [25, 0.1, 250, 300, 250], [50, 0.1, 250, 300, 250], [100, 0.1, 250, 300, 250], [250, 0.1, 250, 300, 250], [300, 0.1, 250, 300, 250], [25, 0.1, 300, 300, 250], [50, 0.1, 300, 300, 250], [100, 0.1, 300, 300, 250], [250, 0.1, 300, 300, 250], [300, 0.1, 300, 300, 250], [25, 0.1, 25, 25, 300], [50, 0.1, 25, 25, 300], [100, 0.1, 25, 25, 300], [250, 0.1, 25, 25, 300], [300, 0.1, 25, 25, 300], [25, 0.1, 50, 25, 300], [50, 0.1, 50, 25, 300], [100, 0.1, 50, 25, 300], [250, 0.1, 50, 25, 300], [300, 0.1, 50, 25, 300], [25, 0.1, 100, 25, 300], [50, 0.1, 100, 25, 300], [100, 0.1, 100, 25, 300], [250, 0.1, 100, 25, 300], [300, 0.1, 100, 25, 300], [25, 0.1, 250, 25, 300], [50, 0.1, 250, 25, 300], [100, 0.1, 250, 25, 300], [250, 0.1, 250, 25, 300], [300, 0.1, 250, 25, 300], [25, 0.1, 300, 25, 300], [50, 0.1, 300, 25, 300], [100, 0.1, 300, 25, 300], [250, 0.1, 300, 25, 300], [300, 0.1, 300, 25, 300], [25, 0.1, 25, 50, 300], [50, 0.1, 25, 50, 300], [100, 0.1, 25, 50, 300], [250, 0.1, 25, 50, 300], [300, 0.1, 25, 50, 300], [25, 0.1, 50, 50, 300], [50, 0.1, 50, 50, 300], [100, 0.1, 50, 50, 300], [250, 0.1, 50, 50, 300], [300, 0.1, 50, 50, 300], [25, 0.1, 100, 50, 300], [50, 0.1, 100, 50, 300], [100, 0.1, 100, 50, 300], [250, 0.1, 100, 50, 300], [300, 0.1, 100, 50, 300], [25, 0.1, 250, 50, 300], [50, 0.1, 250, 50, 300], [100, 0.1, 250, 50, 300], [250, 0.1, 250, 50, 300], [300, 0.1, 250, 50, 300], [25, 0.1, 300, 50, 300], [50, 0.1, 300, 50, 300], [100, 0.1, 300, 50, 300], [250, 0.1, 300, 50, 300], [300, 0.1, 300, 50, 300], [25, 0.1, 25, 100, 300], [50, 0.1, 25, 100, 300], [100, 0.1, 25, 100, 300], [250, 0.1, 25, 100, 300], [300, 0.1, 25, 100, 300], [25, 0.1, 50, 100, 300], [50, 0.1, 50, 100, 300], [100, 0.1, 50, 100, 300], [250, 0.1, 50, 100, 300], [300, 0.1, 50, 100, 300], [25, 0.1, 100, 100, 300], [50, 0.1, 100, 100, 300], [100, 0.1, 100, 100, 300], [250, 0.1, 100, 100, 300], [300, 0.1, 100, 100, 300], [25, 0.1, 250, 100, 300], [50, 0.1, 250, 100, 300], [100, 0.1, 250, 100, 300], [250, 0.1, 250, 100, 300], [300, 0.1, 250, 100, 300], [25, 0.1, 300, 100, 300], [50, 0.1, 300, 100, 300], [100, 0.1, 300, 100, 300], [250, 0.1, 300, 100, 300], [300, 0.1, 300, 100, 300], [25, 0.1, 25, 250, 300], [50, 0.1, 25, 250, 300], [100, 0.1, 25, 250, 300], [250, 0.1, 25, 250, 300], [300, 0.1, 25, 250, 300], [25, 0.1, 50, 250, 300], [50, 0.1, 50, 250, 300], [100, 0.1, 50, 250, 300], [250, 0.1, 50, 250, 300], [300, 0.1, 50, 250, 300], [25, 0.1, 100, 250, 300], [50, 0.1, 100, 250, 300], [100, 0.1, 100, 250, 300], [250, 0.1, 100, 250, 300], [300, 0.1, 100, 250, 300], [25, 0.1, 250, 250, 300], [50, 0.1, 250, 250, 300], [100, 0.1, 250, 250, 300], [250, 0.1, 250, 250, 300], [300, 0.1, 250, 250, 300], [25, 0.1, 300, 250, 300], [50, 0.1, 300, 250, 300], [100, 0.1, 300, 250, 300], [250, 0.1, 300, 250, 300], [300, 0.1, 300, 250, 300], [25, 0.1, 25, 300, 300], [50, 0.1, 25, 300, 300], [100, 0.1, 25, 300, 300], [250, 0.1, 25, 300, 300], [300, 0.1, 25, 300, 300], [25, 0.1, 50, 300, 300], [50, 0.1, 50, 300, 300], [100, 0.1, 50, 300, 300], [250, 0.1, 50, 300, 300], [300, 0.1, 50, 300, 300], [25, 0.1, 100, 300, 300], [50, 0.1, 100, 300, 300], [100, 0.1, 100, 300, 300], [250, 0.1, 100, 300, 300], [300, 0.1, 100, 300, 300], [25, 0.1, 250, 300, 300], [50, 0.1, 250, 300, 300], [100, 0.1, 250, 300, 300], [250, 0.1, 250, 300, 300], [300, 0.1, 250, 300, 300], [25, 0.1, 300, 300, 300], [50, 0.1, 300, 300, 300], [100, 0.1, 300, 300, 300], [250, 0.1, 300, 300, 300], [300, 0.1, 300, 300, 300]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRDn5V_pP-Ve"
      },
      "source": [
        "#gridsearch over defined configurations\n",
        "#evaluating a configuration on test data (unseen but not fully independent from training data) and completely independent data\n",
        "\n",
        "def evaluate_option (option, train_x, test_x, train_y, test_y, test_data_X, test_data_y_numeric, times, verbose = False, opt = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)):\n",
        "    accs = []\n",
        "    models = []\n",
        "    for i in range(0, times):\n",
        "      \n",
        "      current_model = build_model(architecture= build_layers(option[0]), train_x = train_x, labels= labels, opt = opt)\n",
        "      history, acc_normal = train_model(current_model, train_x = train_x, train_y = train_y, test_x = test_x, test_y = test_y, epochs=option[1], batch_size=option[2])\n",
        "      if verbose:\n",
        "        plot_results(history)\n",
        "      _, model_quant = convert_model(model_to_convert=current_model, train_x=train_x)\n",
        "      models.append(model_quant)\n",
        "      eval_quant, acc_quant = evaluate_preds(predictions = predict_tflite(model_quant, np.array(copy.deepcopy(test_x))), test_x = test_x, test_y = test_y, labels=labels, data_columns=parameters)\n",
        "      test_eval_quant, test_acc_quant = evaluate_preds(predictions = predict_tflite(model_quant, np.array(copy.deepcopy(test_data_X))), test_x = test_data_X, test_y = test_data_y_numeric, labels=labels, data_columns = parameters)\n",
        "      accs.append([(acc_quant + test_acc_quant)/2, acc_quant, test_acc_quant])\n",
        "    average_accs = [acc[0] for acc in accs]\n",
        "    test_accs = [acc[1] for acc in accs]\n",
        "    unseen_accs = [acc[2] for acc in accs]\n",
        "    return [sum(average_accs)/times, sum(test_accs)/times, sum(unseen_accs)/times] , models[average_accs.index(max(average_accs))], accs, models\n",
        "\n",
        "\n",
        "def grid_search(architecture_options, X, y_numeric,  test_data_X, test_data_y_numeric, test_set_options = [0.25], epochs_options = [25], batch_size_options = [25], times = 1):\n",
        "  results = []\n",
        "  options = [[arch, epochs, batch_size] for arch in architecture_options  for epochs in epochs_options for batch_size in batch_size_options]\n",
        "  best_option = []\n",
        "  best_accuracy = [0,0,0]\n",
        "  best_unseen_option = []\n",
        "  best_unseen_model = None\n",
        "  best_unseen_accuracy = [0,0,0]\n",
        "\n",
        "  for t in range(0, len(test_set_options)):\n",
        "    test_set_size = test_set_options[t]\n",
        "    train_x, test_x, train_y, test_y = train_test_split(\n",
        "            X, y_numeric, test_size=test_set_size)\n",
        "  \n",
        "    for i in range(0, len(options)):\n",
        "      clear_output()\n",
        "\n",
        "      if os.path.isfile(output_path):\n",
        "        with open(output_path, mode=\"r\") as file:\n",
        "          print(file.read())\n",
        "      print(\"best option: \"+ str(best_option)+ \", accuracy: \"+str(round(best_accuracy[0], 4))+ \" (test: \"+str(round(best_accuracy[1], 4))+\"; unseen: \"+str(round(best_accuracy[2], 4))+\")\")\n",
        "      print(\"best unseen option: \"+ str(best_unseen_option)+ \", accuracy: \"+str(round(best_unseen_accuracy[0], 4))+ \" (test: \"+str(round(best_unseen_accuracy[1], 4))+\"; unseen: \"+str(round(best_unseen_accuracy[2], 4))+\")\\n\")\n",
        "      print(results)\n",
        "      \n",
        "      print(\"\\n\\noption: \"+str(options[i])+\", test_size: \"+str(test_set_size)+ \" (\"+str(t*len(options)+i)+\"/\"+str(len(options)*len(test_set_options))+ \")\\n\\n\")\n",
        "      \n",
        "      try:\n",
        "        \n",
        "        acc, model_quant, _, _ = evaluate_option(options[i],train_x, test_x, train_y, test_y, test_data_X, test_data_y_numeric, times)\n",
        "        chosen_option = [options[i], test_set_size]\n",
        "        results.append([chosen_option, acc])\n",
        "\n",
        "        if acc[0] > best_accuracy[0]:\n",
        "          open(MODEL_TFLITE, \"wb\").write(model_quant)\n",
        "          export_model(mean_str, std_str, labels_str)\n",
        "\n",
        "          best_accuracy = acc\n",
        "          best_option = chosen_option\n",
        "\n",
        "        if acc[2] > best_unseen_accuracy[2]:\n",
        "          best_unseen_model = model_quant\n",
        "          best_unseen_accuracy = acc\n",
        "          best_unseen_option = chosen_option\n",
        "      except RuntimeError:\n",
        "        print(\"runtime error\")\n",
        "  return best_unseen_model, results\n",
        "    \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCXSwJXJsUrO"
      },
      "source": [
        "\n",
        "model,results = grid_search(architectures, X, y_num, test_X, test_y_num, epochs_options = [25], batch_size_options = [20], times = 1, test_set_options = [0.2])\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOPfgkrIktmB",
        "outputId": "ede92606-5e5f-417e-8889-b9cd9582284f"
      },
      "source": [
        "#build single model\n",
        "\n",
        "\n",
        "selected_option = [[250, 0.1, 250], 50, 50]\n",
        "test_size = 0.2\n",
        "ntimes = 5\n",
        "\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "          X, y_num, test_size=test_size)\n",
        "acc, model_quant, accs, models = evaluate_option(selected_option,train_x, test_x, train_y, test_y, test_X, test_y_num, ntimes, verbose=False)\n",
        "\n",
        "print(\"option: \"+ str(selected_option)+ \", accuracy: \"+str(round(acc[0], 4))+ \" (test: \"+str(round(acc[1], 4))+\"; unseen: \"+str(round(acc[2], 4))+\")\")\n",
        "print(\"all models: \\n\"+str(accs))\n",
        "\n",
        "open(MODEL_TFLITE, \"wb\").write(model_quant)\n",
        "export_model(mean_str=mean_str, std_str=std_str, labels_str=labels_str, verbose = False)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpo0p_3mjt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpo0p_3mjt/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprqsnj1cw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmprqsnj1cw/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 23/211, park: 35/185, apartment: 5/325, supermarket: 32/298, clothing_store: 21/259, train: 5/156, bus: 16/250, gym: 0/72, car: 21/107, house: 1/234, nature: 7/82, restaurant: 2/105, cinema: 0/34, concert: 0/18, plane: 0/36, bar: 1/48, \n",
            "predicted wrong overall: 169/2420 (acc: 93.02%)\n",
            "predicted wrong: street: 68/611, park: 116/300, apartment: 13/100, supermarket: 189/710, clothing_store: 237/426, train: 0/100, bus: 48/507, gym: 0/0, car: 61/250, house: 26/101, nature: 73/200, restaurant: 6/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 837/3555 (acc: 76.46%)\n",
            "INFO:tensorflow:Assets written to: /tmp/tmp0og86cpi/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp0og86cpi/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp35t5_t33/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp35t5_t33/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 16/211, park: 28/185, apartment: 4/325, supermarket: 38/298, clothing_store: 22/259, train: 5/156, bus: 25/250, gym: 2/72, car: 17/107, house: 1/234, nature: 6/82, restaurant: 1/105, cinema: 0/34, concert: 0/18, plane: 0/36, bar: 4/48, \n",
            "predicted wrong overall: 169/2420 (acc: 93.02%)\n",
            "predicted wrong: street: 66/611, park: 100/300, apartment: 12/100, supermarket: 201/710, clothing_store: 244/426, train: 0/100, bus: 58/507, gym: 0/0, car: 67/250, house: 45/101, nature: 37/200, restaurant: 9/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 839/3555 (acc: 76.4%)\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpsg60abjy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpsg60abjy/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcwkvr4_a/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpcwkvr4_a/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 22/211, park: 41/185, apartment: 6/325, supermarket: 27/298, clothing_store: 29/259, train: 6/156, bus: 21/250, gym: 0/72, car: 16/107, house: 1/234, nature: 5/82, restaurant: 0/105, cinema: 0/34, concert: 0/18, plane: 0/36, bar: 1/48, \n",
            "predicted wrong overall: 175/2420 (acc: 92.77%)\n",
            "predicted wrong: street: 72/611, park: 121/300, apartment: 14/100, supermarket: 161/710, clothing_store: 242/426, train: 0/100, bus: 89/507, gym: 0/0, car: 53/250, house: 42/101, nature: 60/200, restaurant: 2/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 856/3555 (acc: 75.92%)\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpimb6n4mn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpimb6n4mn/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj1p7m_9q/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpj1p7m_9q/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 16/211, park: 38/185, apartment: 5/325, supermarket: 34/298, clothing_store: 28/259, train: 6/156, bus: 25/250, gym: 1/72, car: 21/107, house: 1/234, nature: 6/82, restaurant: 9/105, cinema: 0/34, concert: 0/18, plane: 0/36, bar: 1/48, \n",
            "predicted wrong overall: 191/2420 (acc: 92.11%)\n",
            "predicted wrong: street: 57/611, park: 104/300, apartment: 29/100, supermarket: 189/710, clothing_store: 246/426, train: 0/100, bus: 75/507, gym: 0/0, car: 67/250, house: 26/101, nature: 73/200, restaurant: 25/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 891/3555 (acc: 74.94%)\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpw32ne3cp/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpw32ne3cp/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpkqy3czfo/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpkqy3czfo/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 12/211, park: 39/185, apartment: 6/325, supermarket: 34/298, clothing_store: 21/259, train: 4/156, bus: 39/250, gym: 1/72, car: 19/107, house: 1/234, nature: 6/82, restaurant: 0/105, cinema: 0/34, concert: 0/18, plane: 0/36, bar: 3/48, \n",
            "predicted wrong overall: 185/2420 (acc: 92.36%)\n",
            "predicted wrong: street: 66/611, park: 133/300, apartment: 20/100, supermarket: 179/710, clothing_store: 240/426, train: 0/100, bus: 88/507, gym: 0/0, car: 54/250, house: 53/101, nature: 77/200, restaurant: 12/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 922/3555 (acc: 74.06%)\n",
            "option: [[250, 0.1, 250], 50, 50], accuracy: 0.841 (test: 0.9265; unseen: 0.7556)\n",
            "all models: \n",
            "[[0.8473611256407574, 0.9301652892561983, 0.7645569620253164], [0.8470798316885774, 0.9301652892561983, 0.7639943741209564], [0.8434491636735595, 0.9276859504132231, 0.7592123769338959], [0.8352207343864421, 0.9210743801652892, 0.7493670886075949], [0.8321003475491393, 0.9235537190082644, 0.7406469760900141]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-Gea9iHbplf",
        "outputId": "94509b19-15b3-4783-f03b-c04339eceba3"
      },
      "source": [
        "#classification with sklearn\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "clf = MLPClassifier(hidden_layer_sizes=(250,250), random_state=1, max_iter=300)\n",
        "train_x, test_x, train_y, test_y = train_test_split(\n",
        "        X, y_num, test_size=0.1)\n",
        "\n",
        "clf = clf.fit(train_x, train_y)\n",
        "predict = clf.predict_proba(test_x)\n",
        "eval, acc = evaluate_preds(predict, test_x, test_y, labels, parameters)\n",
        "\n",
        "\n",
        "predict = clf.predict_proba(test_X)\n",
        "eval, acc = evaluate_preds(predict, test_X, test_y_num, labels, parameters)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predicted wrong: street: 7/131, park: 19/97, apartment: 0/132, supermarket: 10/152, clothing_store: 9/141, train: 1/81, bus: 7/114, gym: 1/40, car: 2/54, house: 0/107, nature: 1/37, restaurant: 1/59, cinema: 0/13, concert: 0/13, plane: 0/18, bar: 0/21, \n",
            "predicted wrong overall: 58/1210 (acc: 95.21%)\n",
            "predicted wrong: street: 74/611, park: 116/300, apartment: 20/100, supermarket: 190/710, clothing_store: 230/426, train: 0/100, bus: 66/507, gym: 0/0, car: 49/250, house: 34/101, nature: 59/200, restaurant: 6/250, cinema: 0/0, concert: 0/0, plane: 0/0, bar: 0/0, \n",
            "predicted wrong overall: 844/3555 (acc: 76.26%)\n"
          ]
        }
      ]
    }
  ]
}